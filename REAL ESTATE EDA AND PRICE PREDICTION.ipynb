{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e60c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b630c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0327ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f949e10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/obinnadinneya/Desktop/OBI_PORTFOLIO'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c63e510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GERMAN CREDITABILITY EDA AND PREDICTION  .ipynb',\n",
       " 'Support-Vector-Machines.ipynb',\n",
       " '.DS_Store',\n",
       " 'Recommender System for movie dataset.ipynb',\n",
       " 'European soccer database EDA.ipynb',\n",
       " 'README.md',\n",
       " 'Airbnb_Sydney_SqlProject.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'REAL ESTATE EDA AND PRICE PREDICTION.ipynb',\n",
       " '.git',\n",
       " 'Exploratory Analysis on data science job salaries 2020-2023.ipynb',\n",
       " 'WebscrappingProject.ipynb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all files in a directory \n",
    "#you can use a for loop to open all files in the directory too\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1a924d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m housing_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "housing_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aadc071",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c89ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the dimension/shape of the dataframe\n",
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761d95e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53704d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the ID column\n",
    "housing_df.drop(\"Id\",axis = 1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52dbee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "sns.heatmap(housing_df.isnull(),yticklabels=False,cmap='viridis',cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a40865",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = housing_df.isnull().sum()*100/len(housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1792b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print columns that have values > 25%\n",
    "#this shows the less influential variables \n",
    "null_df[null_df.values > 25].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.drop(['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], axis =1,\n",
    "               inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df[(null_df.values <= 25) & (null_df.values > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['LotFrontage'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there are still quite a bit of missing vaues in lotfrontage \n",
    "#we can fill it in with the median value \n",
    "\n",
    "housing_df['LotFrontage'].fillna(69.0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returning location where msvnrarea is null as a data frame but for only\n",
    "#MasVnrArea','MasVnrType columns\n",
    "\n",
    "housing_df.loc[housing_df.MasVnrArea.isnull(),['MasVnrArea','MasVnrType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e54862",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[['MasVnrArea','MasVnrType']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we know where the area is null the type is also null\n",
    "#fill in the values \n",
    "housing_df.MasVnrArea.fillna(0,inplace = True)\n",
    "housing_df.MasVnrType.fillna('None', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[['GarageYrBlt','GarageFinish','GarageQual','GarageCond']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b60057",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.loc[housing_df.GarageType.isnull(),['GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588af406",
   "metadata": {},
   "source": [
    "Considering that the garage is empty for these houses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.GarageType.fillna('None', inplace=True)\n",
    "housing_df.GarageYrBlt.fillna(0, inplace=True)\n",
    "housing_df.GarageFinish.fillna('None', inplace=True)\n",
    "housing_df.GarageQual.fillna('None', inplace=True)\n",
    "housing_df.GarageCond.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all rows with Na, NaN , null values\n",
    "housing_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are any na values left \n",
    "#should return an empty series \n",
    "null_df = housing_df.isnull().sum()\n",
    "null_df[null_df.values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(housing_df.isnull(),cmap='viridis',cbar=False,yticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can ask for a statistical summary of each column and specify\n",
    "#the percentile\n",
    "#Adding .T allows us to view the columns as rows and vice versa \n",
    "housing_df.describe([0,0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99,1]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a126867",
   "metadata": {},
   "source": [
    "### To remove outliers which are +-3 standard deviations away from the mean you would have to get rid of anything above the 99 percentile since we only have positive values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeef836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluded object datatypes and printed, assigned a list of non- object\n",
    "#columns\n",
    "number_cols = housing_df.select_dtypes(exclude= 'object').columns\n",
    "number_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(housing_df['MSSubClass'],99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273948bf",
   "metadata": {},
   "source": [
    "### In order to exclude anything higher than 99% of each int/float column then what we have to do is change the value to be the 99%tile value using a for loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(number_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = list(number_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314eb72",
   "metadata": {},
   "source": [
    "### since the variable above is an index not a list to iterate through we have to convert it to a list when we are calling the for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ebe087",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    housing_df.loc[housing_df[i] >= np.percentile(housing_df[i], 99),i] = np.percentile(housing_df[i], 99)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[num_cols].describe([0,0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99,1]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e65cefe",
   "metadata": {},
   "source": [
    "- We can now see that the 99%, 100%tile and max are all the same eliminating the oultiers \n",
    "\n",
    "- Also pool area has zero as the mean so lets get rid of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.drop('PoolArea',axis = 1, inplace = True)\n",
    "num_cols = housing_df.select_dtypes(exclude='object').columns\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical columns \n",
    "\n",
    "cat_cols = housing_df.select_dtypes(include='object').columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we want to print out the value count in eah categorical column\n",
    "\n",
    "# normalize used to get the percentage \n",
    "for i in list(cat_cols):\n",
    "    print(housing_df[i].value_counts(normalize=True))\n",
    "    print('**********************************')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee18f65",
   "metadata": {},
   "source": [
    "Look through the value count and if you see maybe two categories or few where theres big disparity \n",
    "delete that because it wont have a big influence on price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Street','Utilities','LandSlope','Condition2','RoofMatl','Heating','CentralAir','Electrical','Functional',\n",
    "             'PavedDrive','GarageCond','GarageQual','LandContour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485252cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7842c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = housing_df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eabdbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.MSZoning = housing_df.MSZoning.apply(lambda x: 'other' if x not in ('RL','RM') else x)\n",
    "housing_df.LotShape = housing_df.LotShape.apply(lambda x: 'other' if x not in ('Reg','IR1') else x)\n",
    "housing_df.LotConfig = housing_df.LotConfig.apply(lambda x: 'other' if x not in ('Inside','Corner') else x)\n",
    "housing_df.Condition1 = housing_df.Condition1.apply(lambda x: 'other' if x not in ('Norm') else x)\n",
    "housing_df.BldgType = housing_df.BldgType.apply(lambda x: 'other' if x not in ('1Fam') else x)\n",
    "housing_df.HouseStyle = housing_df.HouseStyle.apply(lambda x: 'other' if x not in ('1Story','2Story','1.5Fin') else x)\n",
    "housing_df.RoofStyle = housing_df.RoofStyle.apply(lambda x: 'other' if x not in ('Gable','Hip','1.5Fin') else x)\n",
    "housing_df.RoofStyle = housing_df.RoofStyle.apply(lambda x: 'other' if x not in ('Gable','Hip','1.5Fin') else x)\n",
    "housing_df.RoofStyle = housing_df.RoofStyle.apply(lambda x: 'other' if x not in ('Gable','Hip','1.5Fin') else x)\n",
    "housing_df.Exterior1st = housing_df.Exterior1st.apply(lambda x: 'other' if x not in ('VinylSd','HdBoard','MetalSd','Wd Sdng') else x)\n",
    "housing_df.Exterior2nd = housing_df.Exterior2nd.apply(lambda x: 'other' if x not in ('VinylSd','HdBoard','MetalSd','Wd Sdng') else x)\n",
    "housing_df.MasVnrType = housing_df.MasVnrType.apply(lambda x: 'other' if x not in ('None','none','BrkFace') else x)\n",
    "housing_df.ExterQual = housing_df.ExterQual.apply(lambda x: 'other' if x not in ('TA','Gd') else x)\n",
    "housing_df.ExterCond = housing_df.ExterCond.apply(lambda x: 'other' if x not in ('TA','Gd') else x)\n",
    "housing_df.Foundation = housing_df.Foundation.apply(lambda x: 'other' if x not in ('PConc','CBlock','BrkTil') else x)\n",
    "housing_df.BsmtQual = housing_df.BsmtQual.apply(lambda x: 'other' if x not in ('TA','Gd') else x)\n",
    "housing_df.BsmtQual = housing_df.BsmtQual.apply(lambda x: 'other' if x not in ('TA','Gd') else x)\n",
    "housing_df.BsmtExposure = housing_df.BsmtExposure.apply(lambda x: 'other' if x not in ('No','Av') else x)\n",
    "housing_df.BsmtFinType1 = housing_df.BsmtFinType1.apply(lambda x: 'other' if x not in ('Unf','GLQ','ALQ','BLQ') else x)\n",
    "housing_df.BsmtFinType2 = housing_df.BsmtFinType2.apply(lambda x: 'other' if x not in ('Unf') else x)\n",
    "housing_df.HeatingQC = housing_df.HeatingQC.apply(lambda x: 'other' if x not in ('Ex','TA') else x)\n",
    "housing_df.KitchenQual = housing_df.KitchenQual.apply(lambda x: 'other' if x not in ('TA','Gd') else x)\n",
    "housing_df.GarageType = housing_df.GarageType.apply(lambda x: 'other' if x not in ('Attchd','Detchd') else x)\n",
    "housing_df.GarageType = housing_df.GarageType.apply(lambda x: 'other' if x not in ('Attchd','Detchd') else x)\n",
    "housing_df.SaleType = housing_df.SaleType.apply(lambda x: 'other' if x not in ('WD') else x)\n",
    "housing_df.SaleCondition = housing_df.SaleCondition.apply(lambda x: 'other' if x not in ('Normal') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_to_cat(x):\n",
    "    if x==0:\n",
    "        return 'None'\n",
    "    elif x < 1930:\n",
    "        return 'lt_1930'\n",
    "    elif x > 1930 and x <= 1960:\n",
    "        return 'btw_30_60'\n",
    "    elif x > 1960 and x <= 1990:\n",
    "        return 'btw_60_90'\n",
    "    elif x > 1990:\n",
    "        return 'gt_90'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd68be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['GarageYrBlt'] = housing_df['GarageYrBlt'].apply(lambda x: year_to_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = housing_df.select_dtypes(include='object').columns\n",
    "num_cols = housing_df.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea735d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,28))\n",
    "for i,j in zip(num_cols[:-1], range(len(num_cols[:-1]))):\n",
    "    plt.subplot(8,5,j+1)\n",
    "    sns.scatterplot(data=housing_df, x='SalePrice', y=i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf613cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,30))\n",
    "for i,j in zip(cat_cols, range(len(cat_cols))):\n",
    "    plt.subplot(8,5,j+1)\n",
    "    plt.xticks(rotation=45)\n",
    "    sns.boxplot(data=housing_df, y='SalePrice', x=i)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ec6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,22))\n",
    "sns.heatmap(housing_df.corr(),cmap='RdYlGn', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.drop(columns='Neighborhood',inplace=True)\n",
    "housing_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b880ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = housing_df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_cols,cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d870684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a new data frame with only dummmy categorical data and num columns \n",
    "\n",
    "dummies_df = housing_df[num_cols]\n",
    "\n",
    "for i in cat_cols:\n",
    "    temp = pd.get_dummies(housing_df[i],drop_first=True)\n",
    "    dummies_df = pd.concat([dummies_df,temp],axis=1)\n",
    "\n",
    "dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3238a",
   "metadata": {},
   "source": [
    "## Lets split our data , Train our linear model , predict house sales and Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummies_df.drop(columns='SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dummies_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432483c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b64cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e2713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTIONS \n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=70)\n",
    "g=sns.scatterplot(x=y_test,y=predictions)\n",
    "g.set_xlabel('y_test',fontdict={'size':15})\n",
    "g.set_ylabel('Predictions',fontdict={'size':15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a08875",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(y_test-predictions,bins=100,kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebaa357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "MAE = metrics.mean_absolute_error(y_test,predictions)\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test,predictions)\n",
    "\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "R2 = metrics.r2_score(y_test,predictions)\n",
    "\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'MSE: {MSE}')\n",
    "print(f'RMSE: {RMSE}')\n",
    "print(f'R^2: {R2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0def9a",
   "metadata": {},
   "source": [
    "Average Saleprice = $182000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame(data=lm.coef_,index=X.columns,columns=['Coefficients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = num_cols.drop('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try some PCA PRINCIPLE CONCEPT \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cddfa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbee604",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(housing_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_numdata = scaler.transform(housing_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_numdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA to numcols scaled data \n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647aa43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f117d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(scaled_numdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb781c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pca = pca.transform(scaled_numdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c93367",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348350a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca.components_,columns=num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3cf255",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f131f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_df2 = pd.DataFrame(num_pca,columns=['component1','component2'])\n",
    "\n",
    "for i in cat_cols:\n",
    "    temp = pd.get_dummies(housing_df[i],drop_first=True)\n",
    "    dummies_df2 = pd.concat([dummies_df2,temp],axis=1)\n",
    "\n",
    "dummies_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a3aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummies_df2\n",
    "y = dummies_df['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db47e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791854f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_predictions = lmodel2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa578fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=70)\n",
    "g=sns.scatterplot(x=y_test,y=pca_predictions)\n",
    "g.set_xlabel('y_test',fontdict={'size':15})\n",
    "g.set_ylabel('pca_predictions',fontdict={'size':15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1482b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISTRIBUTION GRAPH OF RESIDUALS \n",
    "sns.displot(y_test-pca_predictions,bins=100,kde=True)\n",
    "plt.ylim(0.0,50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36177d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = metrics.mean_absolute_error(y_test,pca_predictions)\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test,pca_predictions)\n",
    "\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "R2 = metrics.r2_score(y_test,pca_predictions)\n",
    "\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'MSE: {MSE}')\n",
    "print(f'RMSE: {RMSE}')\n",
    "print(f'R^2: {R2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e9977a",
   "metadata": {},
   "source": [
    "#### Using Principle component analysis to compress our numerical columns to two components.This improved our model slightly reducing error and rsquared values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68422aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bc8a38",
   "metadata": {},
   "source": [
    "### USING NEURAL NETWORKS TO PREDICT PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummies_df.drop(columns='SalePrice')\n",
    "y = dummies_df['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=101)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fbe03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit scaler to training data\n",
    "#calcualtes the parameters needed for scaling , hence calculating std dev, min and max \n",
    "#we do it to training set only to avoid data leakage.\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fb4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform training data and test data \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5cd2a",
   "metadata": {},
   "source": [
    "### A commonly used \"rule of thumb\" for deep neural networks is the \"sandwich rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d13ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#layers in neural network 3 hidden layers\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "#output layer one nueron bacoause of what we are trying to predict\n",
    "#no activation function because we want to predict price\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize the models gradient descent using the optimizer argument for example the ADAM\n",
    "model.compile(optimizer='rmsprop',loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y=y_train,epochs=400,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc64e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "#to determine the amount of epochs needed for the minimum amount of loss\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the models loss based on the test set\n",
    "#we used mean squared error\n",
    "model.evaluate(X_test,y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99728d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss on the training set \n",
    "model.evaluate(X_train,y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e615b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame(test_predictions)\n",
    "\n",
    "pred_df = pd.DataFrame(y_test.values,columns=['Test True Y'])\n",
    "\n",
    "pred_df = pd.concat([pred_df,test_predictions],axis=1)\n",
    "\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lets plot the predictions to the original y values\n",
    "sns.scatterplot(x='Test True Y', y= 'Model Predictions',data=pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = metrics.mean_absolute_error(y_test,test_predictions)\n",
    "\n",
    "MSE = metrics.mean_squared_error(y_test,test_predictions)\n",
    "\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "R2 = metrics.r2_score(y_test,test_predictions)\n",
    "\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'MSE: {MSE}')\n",
    "print(f'RMSE: {RMSE}')\n",
    "print(f'R^2: {R2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a30709",
   "metadata": {},
   "source": [
    "- We still see that the Linear regression model perfroms best at predicting the house prices with the lowest error, Although models can be fine tuned to perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd761b79",
   "metadata": {},
   "source": [
    "### THE END "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
